{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "print('imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset\n",
    "train= pd.read_csv(\"../data/train.csv\")\n",
    "df_train= pd.DataFrame(train)\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv(\"../data/test.csv\")\n",
    "df_test= pd.DataFrame(test)  # make dataframe of test data\n",
    "df_test.head(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"size of train data:  \\t\",train.shape) \n",
    "print(\"size of test data:  \\t\",test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The test data has one less column than that in train data: which is because it lack the \"SalePrice\" column and we are going to predict it later by building a machine laearning model - trained with train data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the columns names in train data\n",
    "print(\"columns in train data are: \\n\\n \",train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the column names in test data\n",
    "print(\"columns in test data are:\\n\\n\" ,test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"categorical features are : \\n\\n\",train.select_dtypes(include=['object']).columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numerical Features are : \\n\\n\",train.select_dtypes(exclude=['object']).columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the columns that contains missing values\n",
    "\n",
    "def missing_values():\n",
    "    missing_col= dict()\n",
    "    for i in df_train.columns:\n",
    "        if df_train[i].isnull().sum()>0:\n",
    "            missing_col[i]=df_train[i].isnull().sum()\n",
    "    return missing_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the columns which has more than 50% of the missing values\n",
    "\n",
    "def delete_columns(column):\n",
    "    if df_train[column].isnull().sum() > df_train[column].count()/2:\n",
    "         del train[column]\n",
    "\n",
    "        \n",
    "for column in df_train.columns:\n",
    "    delete_columns(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us now look at the columns that still have missing values/NaNs\n",
    "missing_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Correlation Matrix <b>: With 76 featues we cannot tell which feature is related to house price so to do that we need a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix Heatmap\n",
    "corr_mat= train.corr(method='pearson')\n",
    "fig, axes= plt.subplots(figsize=(12,9))\n",
    "sns.heatmap(corr_mat, square= True,annot= True,vmax= 0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* But there is a lot of data to look at so we need to zoom it into top 10 features most correlated to saleprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 10 heatmap\n",
    "f,axes= plt.subplots(figsize=(10,9))  # size of heatmap\n",
    "k= 10 # no of variables for the heatmap\n",
    "colms= corr_mat.nlargest(k,'SalePrice')['SalePrice'].index # nlargest whenyou want to print largest value and nsmallest for small value\n",
    "cormat= np.corrcoef(train[colms].values)\n",
    "sns.set(font_scale= 1)\n",
    "heat_map= sns.heatmap(cormat,cbar=True, annot= True,square= True,linewidths=None,annot_kws= {'size':15},yticklabels= colms.values,xticklabels= colms.values)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_corr= pd.DataFrame(colms)\n",
    "most_corr.columns= ['most Correlated features']\n",
    "most_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
